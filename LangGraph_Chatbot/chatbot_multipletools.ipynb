{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a697de94",
   "metadata": {},
   "source": [
    "## Creating the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "##tools\n",
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time o\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2, doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv, description=\"Query arxiv papers\")\n",
    "\n",
    "# print(arxiv.name)\n",
    "\n",
    "arxiv.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bcc9e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
